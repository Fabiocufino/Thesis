\chapter{Frameworks}
\section{Introduction to Machine Learning}

Machine learning is a powerful tool that can be used to identify patterns in complex datasets. In the context of particle physics, machine learning algorithms can be used to detect signals from background noise in large datasets generated by detectors. In particular, for the detection of IBD signals from background, machine learning algorithms can be used to identify patterns in the data that are indicative of an IBD event, and to distinguish these signals from the background noise explained above.

\subsection{Supervised Learning}
Supervised learning, a cornerstone of machine learning, operates on the premise of training an algorithm using a labelled dataset. This training ensures that each input aligns with a correct output, with the overarching aim to develop a function that can link input data to output data accurately. A primary task stemming from supervised learning is binary classification, which is responsible for classifying elements of a dataset into one of two possible categories based on inherent features. In the context of this thesis, the emphasis is on applying the binary classification task to the JUNO experiment. The task is to distinguish whether a specific event is an Inverse Beta Decay (IBD) event or a background event.\\
 
Two distinct machine learning algorithms, \textbf{Gradient Boosting Decision Trees} and \textbf{Neural Networks}, are deployed to achieve this.

\section{Decision Tree}
A Decision Tree algorithm, used in supervised machine learning for classification and regression tasks, models the predictive outcome of a target variable based on decision rules inferred from input features. The process involves dissecting the overall dataset into distinct regions, where each region contains data points that are as similar as possible to each other in terms of their target class. Formally, each internal node of the tree represents a decision rule based on an input feature, which bifurcates the data into two child nodes. The decision for splitting the data at each node is determined using a metric known as Information Gain, which in turn is based on the concept of Entropy.

In the context of a binary classification, entropy (H) is a measure of the impurity or disorder within a set (S) of instances. It quantifies the uncertainty involved in predicting the class of a random instance from the set (S). It is mathematically formulated as:

\begin{equation}
	H(S) = - p_{+} \log_{2}(p_{+}) - p_{-} \log_{2}(p_{-})
\end{equation}

Here, $p_+$ and $p_-$ denote the proportions of positive and negative instances in the set S, respectively. Entropy attains a maximum value when the set S contains an equal number of positive and negative instances, reflecting the highest uncertainty.

Information Gain (IG) measures the reduction in entropy achieved by partitioning the instances based on a feature (A). It is the difference between the entropy of the set before the split (H(S)) and the weighted sum of the entropies of each subset resulting from the split. It can be formulated as:

\begin{equation}
	IG(S, A) = H(S) - \sum_{v \in V(A)} \left(\frac{|S_v|}{|S|}\right) H(S_v)
\end{equation}

where $V(A)$ indicates the set of all possible values of feature A.\\
In this equation, $S_v$ denotes the subset of instances in S for which the feature A takes on the value v. $|S_v|$ and $|S|$ are the cardinalities of the sets $S_v$ and $S$, respectively.\\

The algorithm constructs the tree by recursively applying these splits, each time selecting the feature that results in the maximum information gain. This process continues until a stopping criterion is met, such as reaching a pre-specified maximum depth of the tree or a minimum number of samples per leaf.\\


While Decision Trees are straightforward and practical models, their ability to decipher complex patterns in data can be limited. This limitation paves the way for a more advanced technique known as Gradient Boosting Decision Trees. 

\subsection{Gradient Boosting Decision Trees}

 %[] https://www.youtube.com/watch?v=PxgVFp5a0E4&ab_channel=Prof.RyanAhmed
Gradient Boosting is a machine learning algorithm that stems from the concept of boosting, with the application of gradient descent methodology. Its goal is to produce a robust predictive model through the combination of multiple weak learners, typically decision trees.

The primary innovation in Gradient Boosting over classical boosting techniques is its approach to error correction. Instead of modifying the weights of misclassified instances, Gradient Boosting fits each new tree to the residuals (or the negative gradient) of the loss function with respect to the prediction of the existing ensemble of trees. This means each new tree is trained to predict the error of the existing model, thereby iteratively reducing the overall error.

Let's formalize this process:

\begin{enumerate}
	\item \textbf{Initialization}: We begin by initializing our model with a constant value. This is denoted as $F_0(x) = \arg\min_{\gamma} \sum_{i=1}^{N} L(y_i, \gamma)$, where $L(y, F(x))$ represents the loss function, $y$ represents the true target value, and $F(x)$ is the model's prediction for the input features $x$. This constant prediction, $\gamma$, is chosen to minimize the total loss over all $N$ instances. Thus, our initial model starts with a prediction that globally minimizes the loss.
	\item \textbf{Computation of Residuals}: Next, we iteratively construct an ensemble of $M$ trees. For each iteration $m=1$ to $M$, we calculate the residuals as
	\begin{equation}
		r_{im} = - \left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)}
	\end{equation} 
 	for each instance $i=1,2,...,N$. These residuals are essentially the negative gradients (or first derivatives) of the loss function with respect to the model's predictions. They provide a measure of the direction that would decrease the loss function fastest.
	\item \textbf{Fitting a Decision Tree}: After computing the residuals, we fit a new decision tree, $h_m(x)$, to these residuals. This tree is thus trained to predict the negative gradient of the loss function, using train it using the training set 
	${(x_i, r_{im})}_{i=1}^n$. By doing so, it attempts to correct the errors made by the current ensemble model.
	\item \textbf{Model Update}: The model is then updated by applying the rule
	\begin{equation}
		F_m(x) = F_{m-1}(x) + \nu \cdot h_m(x)
	\end{equation}
 	Here, $\nu$ represents the learning rate, a parameter typically less than 1, which controls the contribution of each tree to the final prediction. This essentially adjusts the previous model's prediction in the direction that most decreases the loss.
	\item \textbf{Final Model}: The final model's prediction is given by $F_M(x) = F_0(x) + \sum_{m=1}^{M} \nu \cdot h_m(x)$. In the final ensemble model, each decision tree provides a small correction to the predictions of the previous trees, collaboratively reducing the loss function's value and improving the overall model's performance.
\end{enumerate}


An advanced and highly efficient implementation of this method is XGBoost, which introduces several improvements such as regularization terms in the objective function to prevent overfitting, the computation of the second-order gradient for faster convergence, and built-in mechanisms to handle missing values and enable parallel processing.


\section{Neural Networks}
Neural Networks (NNs) are computational models that draw inspiration from the interconnected structure of the human brain. Each individual computational unit, often referred to as an "artificial neuron" or simply "neuron", is designed to mimic the fundamental working mechanism of a biological neuron.

Let's denote the inputs to an artificial neuron as $ x = [x_1, x_2, ..., x_n] $, a representation analogous to dendrites in a biological neuron. These inputs are linearly transformed by a set of weights, $ w = [w_1, w_2, ..., w_n] $, summed together, and a bias term, $ b $, is added to the result. This operation can be expressed mathematically as:

\[
z = \sum_{i=1}^{n} w_i x_i + b 
\]

The calculated value, $ z $, is then passed through an \textit{activation function}, $ f $, to generate the neuron's output, $ a = f(z) $.


The activation function introduces non-linearity into the model, which is crucial for the network's ability to learn complex patterns. Common choices for $ f $ include the sigmoid, hyperbolic tangent, and ReLU (Rectified Linear Unit) functions.\\

An Artificial Neural Network builds upon the concept of the artificial neuron to form an interconnected assembly of these neurons, structured in layers. An ANN typically comprises an input layer, one or more hidden layers, and an output layer. Each layer may contain one or more neurons, and the layers are fully connected, meaning every neuron in one layer connects with all neurons in the following layer.

The following is a graphical representation of an ANN and a single neuron:

%TODO: Migliorare la qualit√† dell imagine, eliminare la parte scritta

\begin{figure}[h!]
	\centering
	
	\subfloat[Graphic representation of ANN]{
		\includegraphics[width = 0.5\textwidth]{Images/fig_neural_network}
		\label{fig:nn_neuron}
	}
	\centering
	\subfloat[Single Neuron representation]{
		\includegraphics[width = 0.5\textwidth]{Images/nn_neuron}
		

	}
	
\end{figure}


For classification problems, the output layer typically uses a softmax function for multi-class problems to output a probability distribution over the classes, or a sigmoid function for binary classification problems to provide the probability of the positive class.

Training a neural network involves a two-step process: \textit{forward propagation} and \textit{backpropagation}. \\

In \textbf{forward propagation}, the input is passed through the network to generate an output. This output is then compared with the actual target to compute the loss function $ L $.

\textbf{Backpropagation} uses the chain rule of calculus to compute the gradient of $ L $ with respect to the network's parameters, which are then used to update the weights and biases:

\[
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial a} \frac{\partial a}{\partial z} \frac{\partial z}{\partial w}
\]

Here, $ \frac{\partial L}{\partial a} $ is the derivative of the loss function with respect to the activation output, $ \frac{\partial a}{\partial z} $ is the derivative of the activation function, and $ \frac{\partial z}{\partial w} $ is the derivative of the weighted sum with respect to the weights.

Once these gradients are calculated, they are used to update the weights and biases via \textit{gradient descent}, a process that iteratively adjusts the parameters to minimize the loss function:

\[
w_{\text{new}} = w_{\text{old}} - \alpha \frac{\partial L}{\partial w}
\]

\[
b_{\text{new}} = b_{\text{old}} - \alpha \frac{\partial L}{\partial b}
\]

In these equations, $ \alpha $ is the learning rate, a hyperparameter that determines the size of the steps the algorithm takes down the gradient towards the minimum.

The interconnected structure of ANNs, combined with the ability of backpropagation and gradient descent to effectively adjust the model parameters, allows these networks to learn and represent complex, non-linear relationships in the data.
