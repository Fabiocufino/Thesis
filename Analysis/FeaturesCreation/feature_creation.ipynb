{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as up\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#plt.style.use('seaborn-paper')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_BKG = up.open(\"radioactivity_userfile_7days.root\")\n",
    "file_IBD = up.open('../BrutalCuts/unoscillated_IBD_userfile.root') \n",
    "#file_IBD = up.open('ibd_userfile_7days.root') \n",
    "\n",
    "dataset_IBD_all = file_IBD['TRec'].arrays(library = 'np')\n",
    "dataset_BKG = file_BKG['TRec'].arrays(library = 'np')\n",
    "\n",
    "dataset_IBD = {}\n",
    "for key in ['recx', 'recy', 'recz', 'm_QEn', 'm_triggerT']:\n",
    "    dataset_IBD[key] = dataset_IBD_all[key]\n",
    "\n",
    "en_fact = 0.92\n",
    "dataset_IBD[\"m_QEn\"] = dataset_IBD[\"m_QEn\"]*en_fact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198502,)\n",
      "(61870091,)\n",
      "62068593\n"
     ]
    }
   ],
   "source": [
    "print(dataset_IBD[\"m_QEn\"].shape)\n",
    "print(dataset_BKG[\"m_QEn\"].shape)\n",
    "\n",
    "print(dataset_BKG[\"m_QEn\"].shape[0]+dataset_IBD[\"m_QEn\"].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine 2 datasets with the same Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dict(d1, d2):\n",
    "    combined = {}\n",
    "    for k in set(d1.keys()) | set(d2.keys()):\n",
    "        if k in d1 and k in d2 and isinstance(d1[k], np.ndarray) and isinstance(d2[k], np.ndarray):\n",
    "            combined[k] = np.concatenate([d1[k], d2[k]])\n",
    "        elif k in d1:\n",
    "            combined[k] = d1[k]\n",
    "        else:\n",
    "            combined[k] = d2[k]\n",
    "    \n",
    "    provenienza = np.concatenate([np.full_like(d1.get(k, []), 1), np.full_like(d2.get(k, []), 0)])\n",
    "    return {**combined, 'provenienza': provenienza}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = combine_dict(dataset_IBD,dataset_BKG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ord_idx = all_data[\"m_triggerT\"].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_data.keys():\n",
    "    all_data[key] = all_data[key][ord_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(all_data[\"m_triggerT\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE prendo 1M di eventi come sample, di quel milione di eventi, dato che sono combinazione di IBD e BKG, solamente <num_IBD_events> provengono dal dataset IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198502.0\n"
     ]
    }
   ],
   "source": [
    "num_IBD_events = all_data[\"provenienza\"][:1000000].sum()\n",
    "print(num_IBD_events)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questi 10 eventi ci sono sia prompt che delay, servirà per dopo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the ($\\Delta t$, $\\Delta r$, $E_p$, $E_d$, $Label$) features table for all IBD or BKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit, prange, get_num_threads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha argumen 'exponent_time' is snidded in order to not considere events that are 5 $\\tau$ distant from ta prompt event, because the probabiliti is exponetial and this cut help the algorithm to perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel = True)\n",
    "def create_features_handle(x,y,z,E,t,proven, expon_time_cut = 5 * 220e3):\n",
    "\n",
    "    # n = get_num_threads()\n",
    "    n = x.shape[0] - 1\n",
    "\n",
    "    # Creo una vettore \"locale\" che viene scritto/letto solo da un thread per volta -> Poichè ha la dimensione del num threads e ogni thread accede ad un np.zeros(0) a cui fare l'appending\n",
    "    delta_time = n*[np.zeros(0)]\n",
    "    delta_radius = n*[np.zeros(0)]\n",
    "    E_pro = n*[np.zeros(0)]\n",
    "    E_del = n*[np.zeros(0)] \n",
    "    Label = n*[np.zeros(0)]\n",
    "\n",
    "    for i in prange(x.shape[0] - 1):\n",
    "\n",
    "        #Queste due righe di sotto le faccio per risparmiarmi dei cilci\n",
    "        mask = np.logical_and(t>t[i], (t - t[i]) < expon_time_cut)\n",
    "        to_loop = np.nonzero(mask)[0] #-> Ritorna un vettore di indici per i quali mask ha come entrata True \n",
    "        # TIPS, usi la potenza dei np.array per fare la maschera\n",
    "        \n",
    "        # Non ciclo su tutti i possibili eventi, ma solo su quelli che mi possono interessare\n",
    "\n",
    "        for t_index in range(len(to_loop)):\n",
    "            j = to_loop[t_index] #-> Qui dunque j lo fai diventare già solo uno di quelli che servono\n",
    "\n",
    "            if (t[j] - t[i]) < expon_time_cut: \n",
    "\n",
    "                delta_time[i] = np.append(delta_time[i],t[j] - t[i])\n",
    "                delta_radius[i] = np.append(delta_radius[i],np.sqrt((x[i] - x[j])**2 + (y[i] - y[j])**2 + (z[i] - z[j])**2))\n",
    "                E_pro[i] = np.append(E_pro[i], E[i])\n",
    "                E_del[i] = np.append(E_del[i], E[j])\n",
    "                if proven[i] == 1 and proven[j] == 1:\n",
    "                    Label[i] = np.append(Label[i],1)\n",
    "                else:\n",
    "                    Label[i] = np.append(Label[i],0)\n",
    "            else:\n",
    "                print(i, j, t[j] - t[i], 'Qualcosa non va')\n",
    "                break\n",
    "\n",
    "    return delta_time, delta_radius, E_pro, E_del, Label        \n",
    "\n",
    "from iteration_utilities import deepflatten\n",
    "\n",
    "# Funzione per fare un flatten dell'output di Numba\n",
    "def create_features(x,y,z,E,t,proven, expon_time_cut = 5 * 220e3):\n",
    "    res = create_features_handle(x,y,z,E,t,proven, expon_time_cut)\n",
    "    out = []\n",
    "    for vec in res:\n",
    "        out.append(np.asarray(list(deepflatten(vec))))      # -> deep_flatten([1, [2], [[3], 4], 5]) # [1, 2, 3, 4, 5] -> Tanto non conta l'ordine in cui hai fatto il flattern\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\"delta_time\": np.array([]),\n",
    "            \"delta_radius\": np.array([]),\n",
    "            \"E_pro\": np.array([]),\n",
    "            \"E_del\": np.array([]), \n",
    "            \"Label\": np.array([])}\n",
    "\n",
    "cut = 100000\n",
    "features[\"delta_time\"],features[\"delta_radius\"],features[\"E_pro\"],features[\"E_del\"],features[\"Label\"] = create_features(\n",
    "    all_data[\"recx\"][:cut],\n",
    "    all_data[\"recy\"][:cut],\n",
    "    all_data[\"recz\"][:cut],\n",
    "    all_data[\"m_QEn\"][:cut],\n",
    "    all_data[\"m_triggerT\"][:cut],\n",
    "    all_data[\"provenienza\"][:cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBD 33204.0\n",
      "BKG 16965.0\n"
     ]
    }
   ],
   "source": [
    "count = features[\"Label\"].sum()\n",
    "\n",
    "print(\"IBD\", features[\"Label\"].sum())\n",
    "print(\"BKG\", features[\"delta_time\"].shape[0] - count )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float64\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(all_data[\"recx\"].dtype)\n",
    "print(all_data[\"recy\"].dtype)\n",
    "print(all_data[\"recz\"].dtype)\n",
    "print(all_data[\"m_QEn\"].dtype)\n",
    "print(all_data[\"m_triggerT\"].dtype)\n",
    "print(all_data[\"provenienza\"].dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting the cut algorithm to the table of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@njit(parallel = True) \n",
    "def selection(dt,dr,E_pro,E_del, delta_time = 1e6, delta_radius = 1500, min_energy_prompt = 0.7,max_energy_prompt = 12, min_energy_delay = 1.9, max_energy_delay = 2.5, min_energy_delay_carb = 4.4, max_energy_delay_carb = 5.5):\n",
    "    prompt_columns = np.zeros(dt.shape)\n",
    "    delay_columns = np.zeros(dt.shape)\n",
    "    delay_columns_carb = np.zeros(dt.shape)\n",
    "\n",
    "    for i in prange(dt.shape[0]):\n",
    "        if dt[i] < delta_time: \n",
    "            if dr[i] < delta_radius: \n",
    "                if E_pro[i]>= min_energy_prompt and E_pro[i]<= max_energy_prompt:\n",
    "                    if E_del[i]>= min_energy_delay and E_del[i]<= max_energy_delay:\n",
    "                        prompt_columns[i] = 1\n",
    "                        delay_columns[i] = 1\n",
    "                    if E_del[i]>= min_energy_delay_carb and E_del[i]<= max_energy_delay_carb:\n",
    "                        prompt_columns[i] = 1\n",
    "                        delay_columns_carb[i] = 1\n",
    "\n",
    "    return prompt_columns,delay_columns,delay_columns_carb\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_columns, delay_columns, delay_columns_carb = selection(features[\"delta_time\"],features[\"delta_radius\"],features[\"E_pro\"],features[\"E_del\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22410.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_columns.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4534\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (prompt_columns.sum()+delay_columns.sum()+delay_columns_carb.sum())/cut   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22410.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_columns.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque di 10 eventi, sono state trovate, dopo l'algoritmo di cut, 5 coppie Prompt-Delay. L'algoritmo di cuts precedentemente costruito restituisce lo stesso numero di coppie. Nessun evento viene eliminato dall'algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = dataset_IBD\n",
    "fig = px.scatter_matrix(df,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    dimensions = dataset_IBD.keys(),\n",
    "    \n",
    "    title=\"Scatter matrix of features\") # remove underscore\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
