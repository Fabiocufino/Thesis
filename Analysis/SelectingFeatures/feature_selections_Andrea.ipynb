{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as up\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#plt.style.use('seaborn-paper')\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_BKG = up.open(\"radioactivity_userfile_7days.root\")\n",
    "file_IBD = up.open('ibd_userfile_7days.root')\n",
    "\n",
    "dataset_IBD = file_IBD['TRec'].arrays(library = 'np')\n",
    "dataset_BKG = file_BKG['TRec'].arrays(library = 'np')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset è un DICT di NUMPY ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704,)\n",
      "(61870091,)\n",
      "61870795\n"
     ]
    }
   ],
   "source": [
    "print(dataset_IBD[\"m_QEn\"].shape)\n",
    "print(dataset_BKG[\"m_QEn\"].shape)\n",
    "\n",
    "print(dataset_BKG[\"m_QEn\"].shape[0]+dataset_IBD[\"m_QEn\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dict(d1, d2):\n",
    "    combined = {}\n",
    "    for k in set(d1.keys()) | set(d2.keys()):\n",
    "        if k in d1 and k in d2 and isinstance(d1[k], np.ndarray) and isinstance(d2[k], np.ndarray):\n",
    "            combined[k] = np.concatenate([d1[k], d2[k]])\n",
    "        elif k in d1:\n",
    "            combined[k] = d1[k]\n",
    "        else:\n",
    "            combined[k] = d2[k]\n",
    "    \n",
    "    provenienza = np.concatenate([np.full_like(d1.get(k, []), 1), np.full_like(d2.get(k, []), 0)])\n",
    "    return {**combined, 'provenienza': provenienza}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = combine_dict(dataset_IBD,dataset_BKG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Dunque se viene dal dataset IBD si ha che l'evento avrà una Label di 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I'll sort the data in temporal order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     704,      705,      706, ..., 61870792, 61870793, 61870794])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_idx = all_data[\"m_triggerT\"].argsort()\n",
    "ord_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_data.keys():\n",
    "    all_data[key] = all_data[key][ord_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(all_data[\"m_triggerT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creatrion of the $\\Delta r$, $\\Delta t$ and label them IBD or Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, njit, prange, get_num_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit(parallel = False)\n",
    "# def create_features(x,y,z,E,t,proven, expon_time_cut = 5 * 220e3):\n",
    "#     delta_time = np.zeros(0)\n",
    "#     delta_radius = np.zeros(0)\n",
    "#     E_pro = np.zeros(0)\n",
    "#     E_del = np.zeros(0)\n",
    "#     Label = np.zeros(0)\n",
    "\n",
    "#     for i in range(x.shape[0] - 1):\n",
    "#         for j in range(i + 1 , x.shape[0] - 1): # Non devo considerare le coppie j antecedenti perchè sono state già contate da i successivi\n",
    "#             if (t[j] - t[i]) < expon_time_cut: # j è l'indice del delay   \n",
    "#                 delta_time = np.append(delta_time,t[j] - t[i])\n",
    "#                 delta_radius = np.append(delta_radius,np.sqrt((x[i] - x[j])**2 + (y[i] - y[j])**2 + (z[i] - z[j])**2))\n",
    "#                 E_pro = np.append(E_pro, E[i])\n",
    "#                 E_del = np.append(E_del, E[j])\n",
    "#                 if proven[i] == 1 and proven[j] == 1:\n",
    "#                     Label = np.append(Label,1)\n",
    "#                 else:\n",
    "#                     Label = np.append(Label,0)\n",
    "#             else: break\n",
    "#     return delta_time, delta_radius, E_pro, E_del, Label           \n",
    "                    \n",
    "                \n",
    "@njit(parallel = True)\n",
    "def create_features_handle(x,y,z,E,t,proven, expon_time_cut = 5 * 220e3):\n",
    "\n",
    "    # n = get_num_threads()\n",
    "    n = x.shape[0] - 1\n",
    "\n",
    "    # Creo una vettore \"locale\" che viene scritto/letto solo da un thread per volta \n",
    "    delta_time = n*[np.zeros(0)]\n",
    "    delta_radius = n*[np.zeros(0)]\n",
    "    E_pro = n*[np.zeros(0)]\n",
    "    E_del = n*[np.zeros(0)] \n",
    "    Label = n*[np.zeros(0)]\n",
    "\n",
    "    for i in prange(x.shape[0] - 1):\n",
    "\n",
    "        mask = np.logical_and(t>t[i], (t - t[i]) < expon_time_cut)\n",
    "        to_loop = np.nonzero(mask)[0]\n",
    "        \n",
    "        # Non ciclo su tutti i possibili eventi, ma solo su quelli che mi possono interessare\n",
    "\n",
    "        for t_index in range(len(to_loop)): # Non devo considerare le coppie j antecedenti perchè sono state già contate da i successivi\n",
    "            j = to_loop[t_index]\n",
    "\n",
    "            if (t[j] - t[i]) < expon_time_cut: # j è l'indice del delay\n",
    "\n",
    "                delta_time[i] = np.append(delta_time[i],t[j] - t[i])\n",
    "                delta_radius[i] = np.append(delta_radius[i],np.sqrt((x[i] - x[j])**2 + (y[i] - y[j])**2 + (z[i] - z[j])**2))\n",
    "                E_pro[i] = np.append(E_pro[i], E[i])\n",
    "                E_del[i] = np.append(E_del[i], E[j])\n",
    "                if proven[i] == 1 and proven[j] == 1:\n",
    "                    Label[i] = np.append(Label[i],1)\n",
    "                else:\n",
    "                    Label[i] = np.append(Label[i],0)\n",
    "            else:\n",
    "                print(i, j, t[j] - t[i], 'Qualcosa non va')\n",
    "                break\n",
    "\n",
    "    return delta_time, delta_radius, E_pro, E_del, Label        \n",
    "\n",
    "from iteration_utilities import deepflatten\n",
    "\n",
    "# Funzione per fare un flatten dell'output di Numba\n",
    "def create_features(x,y,z,E,t,proven, expon_time_cut = 5 * 220e3):\n",
    "    res = create_features_handle(x,y,z,E,t,proven, expon_time_cut)\n",
    "    out = []\n",
    "    for vec in res:\n",
    "        out.append(np.asarray(list(deepflatten(vec))))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\"delta_time\": np.array([]),\n",
    "            \"delta_radius\": np.array([]),\n",
    "            \"E_pro\": np.array([]),\n",
    "            \"E_del\": np.array([]), \n",
    "            \"Label\": np.array([])}\n",
    "\n",
    "cut = 1000000\n",
    "features[\"delta_time\"],features[\"delta_radius\"],features[\"E_pro\"],features[\"E_del\"],features[\"Label\"] = create_features(\n",
    "    all_data[\"recx\"][:cut],\n",
    "    all_data[\"recy\"][:cut],\n",
    "    all_data[\"recz\"][:cut],\n",
    "    all_data[\"m_QEn\"][:cut],\n",
    "    all_data[\"m_triggerT\"][:cut],\n",
    "    all_data[\"provenienza\"][:cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11238,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"delta_time\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "float32\n",
      "float32\n",
      "float64\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(all_data[\"recx\"].dtype)\n",
    "print(all_data[\"recy\"].dtype)\n",
    "print(all_data[\"recz\"].dtype)\n",
    "print(all_data[\"m_QEn\"].dtype)\n",
    "print(all_data[\"m_triggerT\"].dtype)\n",
    "print(all_data[\"provenienza\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "count = features[\"Label\"].sum()\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
